### `embedding.json`
* One semantic embedding (meaning a vector)
* `modality` tells whether it comes from: 
    * `"audio"`: transcript segment
    * `"visual"`: video frame
* This is what goes into vector db 

---

### `search_response.json`
* Final answer to the user
* `timestamp` = where to jump in the video
* `score` = confidence / similarity score

---

### `transcript.json`
* One spoken segment from the video
* Generated by audio: text processing
* Timestamps are in seconds